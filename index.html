<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Facebook Link Prediction – Assignment 2</title>
  <style>
    :root {
      --fb-blue: #1877f2;
      --fb-blue-light: #42b0ff;
      --fb-dark: #050505;
      --bg-light: #f0f2f5;
      --card-bg: #ffffff;
      --border-soft: #e1e4ea;
    }

    * {
      box-sizing: border-box;
    }

    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
      max-width: 960px;
      margin: auto;
      padding: 2rem 1.5rem 3rem;
      line-height: 1.7;
      background: radial-gradient(circle at top left, #dbe8ff 0, var(--bg-light) 40%, #e3f2ff 100%);
      color: #1c1e21;
    }

    header {
      margin-bottom: 2.5rem;
      padding: 1.75rem 1.5rem 1.5rem;
      border-radius: 16px;
      background: linear-gradient(120deg, var(--fb-blue), #2851a3, var(--fb-blue-light));
      color: #fff;
      box-shadow: 0 10px 25px rgba(0,0,0,0.12);
      position: relative;
      overflow: hidden;
    }

    header::after {
      content: "";
      position: absolute;
      right: -40px;
      bottom: -40px;
      width: 160px;
      height: 160px;
      border-radius: 50%;
      background: rgba(255,255,255,0.18);
      filter: blur(2px);
    }

    h1 {
      margin: 0 0 0.3rem;
      font-size: 2rem;
      font-weight: 700;
      letter-spacing: 0.02em;
    }

    header p {
      margin: 0.2rem 0 0.9rem;
      font-size: 0.98rem;
      opacity: 0.95;
    }

    nav {
      margin-top: 0.4rem;
      display: flex;
      flex-wrap: wrap;
      gap: 0.4rem;
      position: relative;
      z-index: 1;
    }

    nav a {
      text-decoration: none;
      color: #fff;
      font-weight: 500;
      font-size: 0.9rem;
      padding: 0.35rem 0.7rem;
      border-radius: 999px;
      border: 1px solid rgba(255,255,255,0.55);
      background: rgba(0,0,0,0.08);
      backdrop-filter: blur(3px);
      transition: background 0.15s ease, transform 0.1s ease, box-shadow 0.15s ease;
    }

    nav a:hover {
      background: rgba(255,255,255,0.20);
      transform: translateY(-1px);
      box-shadow: 0 2px 8px rgba(0,0,0,0.15);
    }

    .tagline {
      margin-top: 0.6rem;
      font-size: 0.9rem;
      opacity: 0.9;
    }

    .members {
      margin-top: 0.9rem;
      padding: 0.6rem 0.75rem;
      border-radius: 999px;
      background: rgba(0,0,0,0.18);
      font-size: 0.9rem;
      display: inline-flex;
      align-items: center;
      gap: 0.6rem;
    }

    .members-label {
      text-transform: uppercase;
      letter-spacing: 0.05em;
      font-size: 0.78rem;
      opacity: 0.9;
    }

    .members span.name {
      background: rgba(255,255,255,0.22);
      padding: 0.15rem 0.55rem;
      border-radius: 999px;
      font-size: 0.86rem;
      white-space: nowrap;
    }

    section {
      margin-bottom: 2rem;
      background: var(--card-bg);
      padding: 1.5rem 1.4rem 1.6rem;
      border-radius: 14px;
      border: 1px solid var(--border-soft);
      box-shadow: 0 2px 9px rgba(0,0,0,0.03);
      position: relative;
    }

    section::before {
      content: "";
      position: absolute;
      top: 0;
      left: 0;
      width: 4px;
      height: 100%;
      border-radius: 14px 0 0 14px;
      background: linear-gradient(to bottom, var(--fb-blue), var(--fb-blue-light));
      opacity: 0.75;
    }

    section h2 {
      margin-top: 0;
      margin-bottom: 0.6rem;
      font-weight: 650;
    }

    section h3 {
      margin-top: 1.2rem;
      margin-bottom: 0.4rem;
      font-size: 1.05rem;
    }

    img {
      max-width: 100%;
      border-radius: 10px;
      margin: 0.75rem 0 1.1rem;
      border: 1px solid var(--border-soft);
      box-shadow: 0 4px 12px rgba(0,0,0,0.06);
    }

    ul {
      padding-left: 1.3rem;
      margin-top: 0.3rem;
    }

    li {
      margin-bottom: 0.2rem;
    }

    .code {
      background: #18181b;
      color: #f5f5f5;
      padding: 0.8rem;
      border-radius: 8px;
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      white-space: pre-wrap;
      font-size: 0.87rem;
      border: 1px solid #2e2e32;
    }

    .pill-row {
      display: flex;
      flex-wrap: wrap;
      gap: 0.4rem;
      margin: 0.4rem 0;
    }

    .pill {
      font-size: 0.8rem;
      padding: 0.18rem 0.55rem;
      border-radius: 999px;
      border: 1px solid var(--border-soft);
      background: #fefefe;
    }

    footer {
      text-align: center;
      margin-top: 2rem;
      font-size: 0.88rem;
      color: #555;
    }

    @media (max-width: 640px) {
      body {
        padding: 1.3rem 1rem 2.5rem;
      }
      header {
        padding: 1.4rem 1.2rem 1.2rem;
      }
      h1 {
        font-size: 1.6rem;
      }
    }
  </style>
</head>

<body>
  <header>
    <h1>Predicting Facebook Friendships</h1>
    <p>Assignment 2 • Data Mining and Recommender Systems</p>
    <p class="tagline">
      Modeling how network structure in the Facebook friendship graph relates to the probability of a future connection.
    </p>

    <div class="members">
      <span class="members-label">Group Members</span>
      <span class="name">Shaily Nieves Adame</span>
      <span class="name">Tatianna Sanchez</span>
    </div>

    <nav>
      <a href="#task">Task</a>
      <a href="#eda">EDA</a>
      <a href="#features">Features</a>
      <a href="#models">Models</a>
      <a href="#results">Results</a>
      <a href="#discussion">Discussion</a>
    </nav>
  </header>

  <section id="task">
    <h2>1. Predictive Task</h2>
    <p>
      The objective of this project is to <strong>predict whether two Facebook users are friends</strong>
      based solely on the structure of the social network. This is framed as a supervised
      <strong>binary classification</strong> problem, also known as <strong>link prediction</strong>.
    </p>

    <h3>Input (Features)</h3>
    <p>For each candidate pair of users \((u, v)\), we compute graph-based features derived from the current friendship network:</p>
    <ul>
      <li>Number of common friends (common neighbors)</li>
      <li>Jaccard similarity of their friend sets</li>
      <li>Preferential attachment score (product of degrees)</li>
      <li>Adamic–Adar index (weighted common neighbors)</li>
    </ul>

    <h3>Target Variable</h3>
    <p>
      The target label indicates whether an undirected edge between users <code>u</code> and <code>v</code> exists in the graph:
    </p>
    <div class="pill-row">
      <span class="pill">y = 1 → existing friendship (edge)</span>
      <span class="pill">y = 0 → non-edge (randomly sampled pair)</span>
      <span class="pill">Task type: classification</span>
    </div>

    <h3>Evaluation Metrics</h3>
    <p>
      Since link prediction is fundamentally about <strong>ranking</strong> likely connections,
      we evaluate using:
    </p>
    <ul>
      <li><strong>ROC AUC</strong> – how well the model ranks true edges above non-edges.</li>
      <li><strong>Average Precision (AP)</strong> – summarizing the precision–recall curve.</li>
    </ul>
  </section>

  <section id="eda">
    <h2>2. Data & Exploratory Analysis</h2>

    <h3>Facebook Friendship Graph</h3>
    <p>
      The dataset is the well-known <strong>Facebook combined</strong> friendship network.
      Nodes represent users and undirected edges represent mutual friendships.
      After loading the edge list, we obtained:
    </p>
    <ul>
      <li><strong>4,039</strong> users (nodes)</li>
      <li><strong>88,234</strong> friendships (edges)</li>
      <li><strong>Average degree ≈ 43.7</strong></li>
      <li><strong>Density ≈ 0.0108</strong> (sparse graph)</li>
    </ul>

    <h3>Degree Distribution</h3>
    <p>
      We plot the degree distribution on linear, log, and log–log scales.
      Most users have a moderate number of friends, while a few users act as hubs with very high degree.
      The heavy tail in the log–log plot is consistent with <strong>scale-free</strong> behavior.
    </p>
    <img src="plots/degree_distribution.png" alt="Degree Distribution">

    <h3>Clustering & Small-World Structure</h3>
    <p>
      Using a sample of 2,000 nodes, we computed local clustering coefficients.
      The mean and median clustering are both around 0.6, indicating that
      a user's friends are very likely to also be friends with each other.
    </p>
    <p>
      We also approximated shortest path lengths using BFS from 40 random starting nodes.
      The average shortest path is under 4 hops and the 90th percentile is around 5 hops,
      confirming <strong>small-world</strong> behavior: short distances and high clustering.
    </p>
    <img src="plots/clustering_and_paths.png" alt="Clustering and Shortest Paths">
  </section>

  <section id="features">
    <h2>3. Feature Engineering & Preprocessing</h2>

    <p>
      For each sampled pair of users \((u, v)\), we construct a compact feature vector
      capturing the structural relationship between their neighborhoods in the graph.
      These features are computed from the adjacency list representation of the network.
    </p>

    <h3>Final Feature Set</h3>
    <div class="code">
features(u, v):

  Γ(u) = set of neighbors of u
  Γ(v) = set of neighbors of v

  1. Common Neighbors (CN)
     CN(u, v) = |Γ(u) ∩ Γ(v)|

  2. Jaccard Coefficient (J)
     J(u, v) = |Γ(u) ∩ Γ(v)| / |Γ(u) ∪ Γ(v)|

  3. Preferential Attachment (PA)
     PA(u, v) = log(1 + deg(u) × deg(v))

  4. Adamic–Adar Index (AA)
     AA(u, v) = Σ<sub>w in Γ(u) ∩ Γ(v)</sub> 1 / log(1 + deg(w))
    </div>

    <p>
      We construct a balanced dataset of <strong>20,000 positive edges</strong> and
      <strong>20,000 negative pairs</strong>, compute the above features for each pair,
      and then perform a stratified 70/30 train–test split.
    </p>
  </section>

  <section id="models">
    <h2>4. Models</h2>
    <p>
      We evaluate both simple heuristics and three machine learning models for link prediction:
    </p>

    <h3>Heuristic Baselines</h3>
    <ul>
      <li><strong>Common Neighbors</strong> – uses CN(u, v) directly as a score.</li>
      <li><strong>Jaccard Coefficient</strong> – normalizes common neighbors by union size.</li>
      <li><strong>Preferential Attachment</strong> – scores pairs by deg(u) × deg(v).</li>
      <li><strong>Adamic–Adar</strong> – weighted common neighbors with degree discounting.</li>
    </ul>
    <p>
      These heuristics are widely used in network science and provide strong, interpretable baselines.
    </p>

    <h3>Machine Learning Models</h3>
    <ul>
      <li>
        <strong>Logistic Regression</strong> – a linear model over the four structural features.
        It serves as a transparent baseline and allows us to see how each feature contributes.
      </li>
      <li>
        <strong>Random Forest Classifier</strong> – an ensemble of decision trees
        trained via bagging. It captures nonlinear interactions between features
        and produces feature importance scores.
      </li>
      <li>
        <strong>Gradient Boosting Classifier</strong> – a boosting-based ensemble
        that adds trees sequentially, each correcting residual errors of the previous ones.
        It is well-suited to ranking-style problems and often yields the best performance.
      </li>
    </ul>
  </section>

  <section id="results">
    <h2>5. Results & Model Comparison</h2>

    <h3>Heuristic Performance</h3>
    <p>
      Using each structural feature individually as a score, we evaluate AUC and Average Precision
      on the held-out test set. Common Neighbors, Jaccard, and Adamic–Adar all achieve very high
      AUC/AP, while Preferential Attachment performs noticeably worse.
    </p>
    <img src="plots/heuristic_comparison.png" alt="Heuristic Comparison">

    <h3>Machine Learning Models</h3>
    <p>
      All three classifiers — Logistic Regression, Random Forest, and Gradient Boosting —
      achieve near-perfect performance on this dataset. The underlying reason is that the
      structural features already capture very strong signals of friendship.
    </p>
    <img src="plots/model_comparison.png" alt="Model Comparison">

    <p>
      Gradient Boosting typically achieves the highest AUC and Average Precision,
      with Random Forest close behind. Logistic Regression is competitive despite its simplicity,
      which highlights how informative the four features are.
    </p>

    <h3>Score Distributions</h3>
    <p>
      For the logistic regression model, we visualize the predicted probabilities for
      positive vs. negative pairs. The distributions are well-separated: true edges cluster
      near probability 1 and non-edges near probability 0, indicating excellent ranking quality.
    </p>
    <img src="plots/score_distribution_lr.png" alt="Logistic Regression Scores">

    <h3>Feature Importances</h3>
    <p>
      Both Random Forest and Gradient Boosting feature importance plots show that:
    </p>
    <ul>
      <li><strong>Common Neighbors</strong> and <strong>Adamic–Adar</strong> are the most important features.</li>
      <li><strong>Jaccard</strong> contributes additional signal.</li>
      <li><strong>Preferential Attachment</strong> has the lowest importance.</li>
    </ul>
    <img src="plots/feature_importances.png" alt="Feature Importances">
  </section>

  <section id="discussion">
    <h2>6. Discussion & Related Work</h2>
    <p>
      Link prediction on social networks has been widely studied in the context of
      friend recommendation, graph mining, and network evolution. Classic approaches
      rely on structural similarity scores such as common neighbors, Jaccard, and
      Adamic–Adar — exactly the heuristics we use as baselines.
    </p>

    <h3>Key Takeaways</h3>
    <ul>
      <li>
        Simple structural features derived from the Facebook friendship graph are
        <strong>highly predictive</strong> of whether an edge exists.
      </li>
      <li>
        Machine learning models (especially Gradient Boosting) slightly improve upon
        individual heuristics, but the gains are modest because the heuristics are already very strong.
      </li>
      <li>
        Feature importance analysis confirms that <strong>triadic closure</strong>
        (friends-of-friends) is the dominant mechanism behind link formation in this network.
      </li>
    </ul>

    <h3>Limitations & Future Work</h3>
    <ul>
      <li>
        Our dataset is static; in reality, friendships form over time.
        A more realistic setup would use <strong>temporal link prediction</strong>.
      </li>
      <li>
        We treat all unobserved edges as negatives, which may mislabel some
        future friendships. Temporal or probabilistic approaches could reduce this issue.
      </li>
      <li>
        Extensions could include <strong>node embeddings</strong> (e.g., Node2Vec) or
        <strong>Graph Neural Networks</strong> to capture higher-order structure.
      </li>
    </ul>
  </section>

  <footer>
    Facebook Link Prediction Project – Assignment 2
  </footer>

</body>
</html>
